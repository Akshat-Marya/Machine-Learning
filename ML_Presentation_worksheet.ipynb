{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Presentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "DEzMmHjotESY",
        "hq9zM_yTtESb",
        "bJl-mOxPtESp",
        "QISUm1vFtESq",
        "FThU_CV_tESt",
        "jW8ujIORtESv",
        "H9u88YwstESw",
        "jp_Yl_ActESx",
        "T7EYftJNtES0",
        "WgIVQI7ZtES5",
        "RKyiogdAtETH",
        "y-1k_nv7tETM",
        "inG6Ov7XtETZ",
        "oXN75p9ltETa",
        "qZ9Ha6rKtETd",
        "L3qZ1AnptETd",
        "DBgvfQfWtETf",
        "OnLLYrROtETg",
        "_YdBtRTmtETj",
        "SqNg4OCptETm",
        "BoUcZCVrtETq",
        "Wy6WOY-WtETq",
        "mWJMVe_dtETr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "DEzMmHjotESY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# What is DNA?"
      ]
    },
    {
      "metadata": {
        "id": "qPhWpbDZtESZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "DNA is  a long molecule made up by 4  basic elements A,C,G and T. More simply, it is a long sequeence of 4 characters, that when put together in different patterns, perform different functionallities.\n",
        "\n",
        "Each human has the same structure, but with different patterns of these units in its genomes.\n",
        "\n",
        "Which means, we can basically pinpoint te patterns in the sequence that are responsible for specific functions, for example with diseases, more people with a particular diseases would have similar patterns in their DNA!"
      ]
    },
    {
      "metadata": {
        "id": "Mvxm3UhZtESb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Obtained the full consensus first draft of human genome in 2003, it took 10 years, about 3 billion dollars. Since we don't have that kind of money..."
      ]
    },
    {
      "metadata": {
        "id": "hq9zM_yTtESb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let's make our own DNA in python!"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "ncL3VLGptESc",
        "colab_type": "code",
        "outputId": "17fdf41b-2cb8-4ce4-aa32-b4415ad46d3b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# initialise list\n",
        "human_genome = []\n",
        "\n",
        "def making_genome():\n",
        "    # make it add randomly to the list\n",
        "    for i in range(100):\n",
        "        a = random.randint(0,3)\n",
        "        if a==0:\n",
        "            human_genome.append('A')\n",
        "        elif a==1:\n",
        "            human_genome.append('C')\n",
        "        elif a==2:\n",
        "            human_genome.append('G')\n",
        "        elif a==3:\n",
        "            human_genome.append('T')\n",
        "    # return the list\n",
        "    return (human_genome)\n",
        "\n",
        "    \n",
        "#genome sequence with 100\n",
        "first_genome = making_genome()\n",
        "print(\"First Genome:\", first_genome)\n",
        "print(\"len(first_genome)\",len(first_genome))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Genome: ['C', 'G', 'C', 'C', 'C', 'C', 'T', 'C', 'C', 'A', 'A', 'C', 'T', 'A', 'T', 'T', 'T', 'C', 'C', 'A', 'A', 'A', 'T', 'C', 'T', 'G', 'A', 'T', 'G', 'G', 'T', 'T', 'C', 'A', 'G', 'G', 'A', 'G', 'G', 'A', 'A', 'T', 'G', 'C', 'C', 'C', 'T', 'T', 'A', 'A', 'A', 'C', 'G', 'A', 'T', 'G', 'A', 'A', 'G', 'A', 'A', 'A', 'T', 'G', 'T', 'A', 'C', 'C', 'T', 'T', 'T', 'T', 'G', 'C', 'A', 'A', 'C', 'G', 'C', 'A', 'C', 'G', 'C', 'G', 'G', 'C', 'G', 'G', 'G', 'G', 'T', 'C', 'A', 'C', 'G', 'G', 'A', 'C', 'A', 'C']\n",
            "len(first_genome) 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cYsMo3_DtESg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## When money was put to good use by the people at NIH and Encode, they color coded it!"
      ]
    },
    {
      "metadata": {
        "id": "7590S8yptESh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![youtube_full_process.png](attachment:youtube_full_process.png)\n",
        "https://www.youtube.com/watch?v=lX76DzZdjvQ"
      ]
    },
    {
      "metadata": {
        "id": "WZMlMRsUtESi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## What it Acutally means\n",
        "![youtube_in_detail_pic.png](attachment:youtube_in_detail_pic.png)\n",
        "https://www.youtube.com/watch?v=lX76DzZdjvQ"
      ]
    },
    {
      "metadata": {
        "id": "Bd-iTjvTtESj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As, we can see from the image above, the molecule can be broken down into chromatin fiber, which is made up for DNA, which is a long string of random sequence of A,C,G and T basic units.\n",
        "\n",
        "<b>The DNA can be seen to attaract/wrap around other nucleosome, and perform some functionality.</b>\n",
        "\n",
        "If we are able to \"learn\" what patterns of the A,C,G and T are responsible for which specific functionality of that molecule and then molecule as a whole, we can treat diseases, improve our DNA, and other miraculous things like make up a new species from scratch!\n",
        "\n",
        "\n",
        "Now, consider this as a recipie book. Where the genome contains all the ingredients that we need to make everything in the book.\n",
        "While different patterns that perform different functionalities, are dishes in the book. \n",
        "<b>But, the problem is </b>, that the recipie book is in a language that we do not understand. And that is where Deep learning comes in.\n",
        "\n",
        "\n",
        "<b>We now have something amazing.</b> We have a reciepie book, and all the ingredients to make all the dishes in the book. We just need to figure out what ingredients do what, so that we can combine them to make something that would be useful to us!\n",
        "\n",
        "<i>From medicines, to treating illnesses, and someday I believe forced human evolution...</i>"
      ]
    },
    {
      "metadata": {
        "id": "pYy04MzotESk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Leave this part out for now\n",
        "\n",
        "\n",
        "<b>We therefore use three other techniques to detect long-term interactions.</b>\n",
        "- First,\n",
        "most convolutional neural networks (CNNs) use small convolution filters. Using larger filters\n",
        "already at an early stage in the network allows for early detection of long-term interactions without\n",
        "the need of fully connected layers with a large input. \n",
        "- Second, \n",
        "a deep network similar to the ResNet (He et al., 2015) or Inception (Szegedy et al., 2015) network design prevents features found in early layers from vanishing. Also, they reduce the size of the layers such that the final fully connected\n",
        "layers have a smaller input and donâ€™t require a huge number of parameters.\n",
        "- Third, \n",
        "we propose a novel kind of DNA representation by mapping DNA sequences to higher-dimensional images using\n",
        "space-filling curves."
      ]
    },
    {
      "metadata": {
        "id": "rmac5zzJtESk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Space-filling curves map\n",
        "\n",
        "\n",
        "A 1-dimensional line to a 2-dimensional space by\n",
        "mapping each element of the sequence to a pixel in the 2D image. By doing so, proximal elements of\n",
        "the sequence will stay in close proximity to one another, while the distance between distal elements\n",
        "is reduced."
      ]
    },
    {
      "metadata": {
        "id": "tjdUcb4ZtESl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hilbert curve \n",
        "\n",
        "Is a line drawn on a 2D matrix that represents an infinite space where the line hits each point in that space, filling it completely."
      ]
    },
    {
      "metadata": {
        "id": "i0uJuwZLtESm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Hilbert_curve.gif](attachment:Hilbert_curve.gif)"
      ]
    },
    {
      "metadata": {
        "id": "_Tk5OpyVtESn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://commons.wikimedia.org/wiki/File:Hilbert_curve.gif"
      ]
    },
    {
      "metadata": {
        "id": "nUrhi04ptESn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Trying to visualise how it might cover all the points in infinite space..."
      ]
    },
    {
      "metadata": {
        "id": "OtkKQ0NltESo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Hilbert_curve_traversal.gif](attachment:Hilbert_curve_traversal.gif)\n",
        "https://www.reddit.com/r/mathpics/comments/4eiqj9/hilbert_curve_animation_experiments/"
      ]
    },
    {
      "metadata": {
        "id": "bJl-mOxPtESp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's try to relate it"
      ]
    },
    {
      "metadata": {
        "id": "QISUm1vFtESq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Hilbert curves an interesting choice for representing DNA sequence as two-dimensional images. \n",
        "- \n",
        "Is a basic requirement for mapping short-term\n",
        "sequential relationships, which are ubiquitous in DNA (such as codons, motifs or intron-exon structure).\n",
        "\n",
        " \n"
      ]
    },
    {
      "metadata": {
        "id": "s7tJgw_jtESr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- \n",
        "Relates to the structure of the chromatin, which - without all details being fully understood is tightly packaged and organized in general. Results from Elgin (2012) indicate that when arranging\n",
        "DNA sequence based on Hilbert curves, contiguous areas belonging to identical chromatin\n",
        "states cover rectangular areas. In particular, the combination of (i) and (ii) motivate the application\n",
        "of convolutional layers on Hilbert curves derived from DNA sequence: rectangular subspaces, in\n",
        "other words, submatrices encoding the convolution operations, contain a minimum amount of disconnected\n",
        "pieces of DNA."
      ]
    },
    {
      "metadata": {
        "id": "ZCwIGGMktESs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- \n",
        "Finally is beneficial insofar as long-term interactions affecting DNA\n",
        "can also be mapped. This in particular applies to so-called enhancers and silencers, which exert\n",
        "positive (enhancer) or negative (silencer) effects on the activity of regions harboring genes, even\n",
        "though they may be far apart from those regions in terms of sequential distance."
      ]
    },
    {
      "metadata": {
        "id": "FThU_CV_tESt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### DNA sequence classification is the task of determining whether a sequence S belongs to an existing class"
      ]
    },
    {
      "metadata": {
        "id": "W6BJ8qqNtESu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The author mentions some of the other works and their methods used, such as Deep neural networks (LeCun et al., 2015) form\n",
        "the most recent class of methods used for DNA sequence classification (R.R. Bhat, 2016; Salimans\n",
        "et al., 2016; Zhou & Troyanskaya, 2015; Angermueller et al., 2016).\n",
        "###### Only Nguyen et al. (2016) use a CCN as the author do."
      ]
    },
    {
      "metadata": {
        "id": "jW8ujIORtESv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### There are two major differences between their approach and ours. \n",
        "- First and foremost, \n",
        "The model architecture is different: the network in Nguyen\n",
        "et al. (2016) consists of two convolution layers followed by pooling layers, a fully connected layer and a sigmoid layer, while our model architecture is deeper, uses residual connections to reuse the learned features, has larger convolution filters and has small layers preceding the fully connected layers (see Methods). \n",
        "\n",
        "\n",
        "\n",
        "- Second, \n",
        "While we use a space-filling curve to transform the sequence data into an image-like tensor, Nguyen et al. (2016) keep the sequential form of the input data.\n",
        "\n",
        "\n",
        "\n",
        "#### Another paper that uses Hilbert Curves: \n",
        "Published as a conference paper at ICLR 2018 Apart from Elgin (2012), the only example we are aware of where Hilbert curves were used to map DNA sequence into two-dimensional space is from Anders (2009), who demonstrated the power of Hilbert curves for visualizing DNA. Beyond our theoretical considerations, these last two studies suggest there are practical benefits of mapping DNA using Hilbert curves."
      ]
    },
    {
      "metadata": {
        "id": "H9u88YwstESw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Their Work Contributions:\n",
        "\n",
        "- First, we predict chromatin state using a CNN that, in terms of architecture,\n",
        "resembles conventional CNNs for image classification and is designed for detecting distal\n",
        "relations.\n",
        "\n",
        "\n",
        "- Second, we propose a method to transform DNA sequence patches into two-dimensional\n",
        "image-like arrays to enhance the strengths of CNNs using space-filling curves, in particular the\n",
        "Hilbert curve."
      ]
    },
    {
      "metadata": {
        "id": "jp_Yl_ActESx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Our experiments demonstrate the benefits of our approach: \n",
        "\n",
        "- The developed CNN decisively outperforms all existing approaches for predicting the chromatin state in terms of prediction\n",
        "performance measures as well as runtime, an improvement which is further enhanced by the convolution of DNA sequence to a 2D image. \n",
        "\n",
        "In summary, we present a novel, powerful way to harness\n",
        "the power of CNNs in image classification for predicting biologically relevant features from primary\n",
        "DNA sequence."
      ]
    },
    {
      "metadata": {
        "id": "1xRzkHGNtESy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# How They Did It!\n",
        "\n",
        "\n",
        "### We transform DNA sequences into images through three steps. \n",
        "- First, we represent a sequence as a list of k-mers. \n",
        "- Next, we transform each k-mer into a one-hot vector, which results in the sequence being represented as a list of <b><u>one-hot vectors</u></b>. \n",
        "- Finally, we create an image-like tensor by assigning each element of the list of k-mers to a pixel in the image using Hilbert curves."
      ]
    },
    {
      "metadata": {
        "id": "cTG1yJw1tESz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<b>The first step in our approach is thus to transform the DNA sequence into a\n",
        "list of k-mers.</b>\n",
        "\n",
        "\n",
        "\n",
        "Through preliminary experiments, we found that\n",
        "k = 4 yields the best performance: lower values for k result in reduced accuracy, while higher\n",
        "values yield a high risk of overfitting."
      ]
    },
    {
      "metadata": {
        "id": "T7EYftJNtES0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#### A one-hot vector has a one in the position that corresponds to the word the position\n",
        "![one-hot-vector_slide.png](attachment:one-hot-vector_slide.png)\n"
      ]
    },
    {
      "metadata": {
        "id": "3GC6jVJ1tES2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "In order to represent all k-mers in a DNA sequence,\n",
        "we need a vector of length 4k, as this is the number of words of length k that can be constructed\n",
        "from the alphabet \n",
        "\n",
        "###### {A,C,G,T}. \n",
        "For example, if we wish to represent all 1-mers, we can do so using a one-hot vector of length 4 where, \n",
        "- A corresponds to [1 0 0 0], \n",
        "- C to [0 1 0 0], \n",
        "- G to [0 0 1 0],\n",
        "- T to [0 0 0 1]. \n",
        "\n",
        "\n",
        "\n",
        "In our case, the DNA sequence is represented as a list of 4-mers, which can be converted\n",
        "to a list of one-hot vectors each of length 4^4 = 256."
      ]
    },
    {
      "metadata": {
        "id": "mMy4rlTCtES4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![K_mer.jpg](attachment:K_mer.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "WgIVQI7ZtES5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The formula for  4^k where k length of the subset you wanna take and the research paper has indexed the data using 4-mer,\n",
        "\n",
        "\n",
        "## Which then means, each pixel is now asssigned a one hot vector of length 256, where each of those 256 elements represent one pattern of all the possible words of length 4 that can be made from the input sequence. <br>"
      ]
    },
    {
      "metadata": {
        "id": "v9PcE7F0tES5",
        "colab_type": "code",
        "outputId": "ed00f50b-de88-4318-9bec-80159849186c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from itertools import product\n",
        "alphabets=['A','C','G','T']\n",
        "keywords = [''.join(i) for i in itertools.product(alphabets, repeat = 5)]\n",
        "print(len(keywords))\n",
        "print(keywords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "['AAAA', 'AAAC', 'AAAG', 'AAAT', 'AACA', 'AACC', 'AACG', 'AACT', 'AAGA', 'AAGC', 'AAGG', 'AAGT', 'AATA', 'AATC', 'AATG', 'AATT', 'ACAA', 'ACAC', 'ACAG', 'ACAT', 'ACCA', 'ACCC', 'ACCG', 'ACCT', 'ACGA', 'ACGC', 'ACGG', 'ACGT', 'ACTA', 'ACTC', 'ACTG', 'ACTT', 'AGAA', 'AGAC', 'AGAG', 'AGAT', 'AGCA', 'AGCC', 'AGCG', 'AGCT', 'AGGA', 'AGGC', 'AGGG', 'AGGT', 'AGTA', 'AGTC', 'AGTG', 'AGTT', 'ATAA', 'ATAC', 'ATAG', 'ATAT', 'ATCA', 'ATCC', 'ATCG', 'ATCT', 'ATGA', 'ATGC', 'ATGG', 'ATGT', 'ATTA', 'ATTC', 'ATTG', 'ATTT', 'CAAA', 'CAAC', 'CAAG', 'CAAT', 'CACA', 'CACC', 'CACG', 'CACT', 'CAGA', 'CAGC', 'CAGG', 'CAGT', 'CATA', 'CATC', 'CATG', 'CATT', 'CCAA', 'CCAC', 'CCAG', 'CCAT', 'CCCA', 'CCCC', 'CCCG', 'CCCT', 'CCGA', 'CCGC', 'CCGG', 'CCGT', 'CCTA', 'CCTC', 'CCTG', 'CCTT', 'CGAA', 'CGAC', 'CGAG', 'CGAT', 'CGCA', 'CGCC', 'CGCG', 'CGCT', 'CGGA', 'CGGC', 'CGGG', 'CGGT', 'CGTA', 'CGTC', 'CGTG', 'CGTT', 'CTAA', 'CTAC', 'CTAG', 'CTAT', 'CTCA', 'CTCC', 'CTCG', 'CTCT', 'CTGA', 'CTGC', 'CTGG', 'CTGT', 'CTTA', 'CTTC', 'CTTG', 'CTTT', 'GAAA', 'GAAC', 'GAAG', 'GAAT', 'GACA', 'GACC', 'GACG', 'GACT', 'GAGA', 'GAGC', 'GAGG', 'GAGT', 'GATA', 'GATC', 'GATG', 'GATT', 'GCAA', 'GCAC', 'GCAG', 'GCAT', 'GCCA', 'GCCC', 'GCCG', 'GCCT', 'GCGA', 'GCGC', 'GCGG', 'GCGT', 'GCTA', 'GCTC', 'GCTG', 'GCTT', 'GGAA', 'GGAC', 'GGAG', 'GGAT', 'GGCA', 'GGCC', 'GGCG', 'GGCT', 'GGGA', 'GGGC', 'GGGG', 'GGGT', 'GGTA', 'GGTC', 'GGTG', 'GGTT', 'GTAA', 'GTAC', 'GTAG', 'GTAT', 'GTCA', 'GTCC', 'GTCG', 'GTCT', 'GTGA', 'GTGC', 'GTGG', 'GTGT', 'GTTA', 'GTTC', 'GTTG', 'GTTT', 'TAAA', 'TAAC', 'TAAG', 'TAAT', 'TACA', 'TACC', 'TACG', 'TACT', 'TAGA', 'TAGC', 'TAGG', 'TAGT', 'TATA', 'TATC', 'TATG', 'TATT', 'TCAA', 'TCAC', 'TCAG', 'TCAT', 'TCCA', 'TCCC', 'TCCG', 'TCCT', 'TCGA', 'TCGC', 'TCGG', 'TCGT', 'TCTA', 'TCTC', 'TCTG', 'TCTT', 'TGAA', 'TGAC', 'TGAG', 'TGAT', 'TGCA', 'TGCC', 'TGCG', 'TGCT', 'TGGA', 'TGGC', 'TGGG', 'TGGT', 'TGTA', 'TGTC', 'TGTG', 'TGTT', 'TTAA', 'TTAC', 'TTAG', 'TTAT', 'TTCA', 'TTCC', 'TTCG', 'TTCT', 'TTGA', 'TTGC', 'TTGG', 'TTGT', 'TTTA', 'TTTC', 'TTTG', 'TTTT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MkigZnMmtES9",
        "colab_type": "code",
        "outputId": "c7c22f9b-cfa3-4f60-e4df-a72278f4aa39",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from itertools import product\n",
        "alphabets=['A','C','G','T']\n",
        "keywords = [''.join(i) for i in itertools.product(alphabets, repeat = 3)]\n",
        "print(len(keywords))\n",
        "print(keywords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64\n",
            "['AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT', 'AGA', 'AGC', 'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT', 'CAA', 'CAC', 'CAG', 'CAT', 'CCA', 'CCC', 'CCG', 'CCT', 'CGA', 'CGC', 'CGG', 'CGT', 'CTA', 'CTC', 'CTG', 'CTT', 'GAA', 'GAC', 'GAG', 'GAT', 'GCA', 'GCC', 'GCG', 'GCT', 'GGA', 'GGC', 'GGG', 'GGT', 'GTA', 'GTC', 'GTG', 'GTT', 'TAA', 'TAC', 'TAG', 'TAT', 'TCA', 'TCC', 'TCG', 'TCT', 'TGA', 'TGC', 'TGG', 'TGT', 'TTA', 'TTC', 'TTG', 'TTT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wN-koFNItETA",
        "colab_type": "code",
        "outputId": "49218b5c-7926-4604-d83c-28c044040999",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from itertools import product\n",
        "alphabets=['A','C','G','T']\n",
        "keywords = [''.join(i) for i in itertools.product(alphabets, repeat = 4)]\n",
        "print(len(keywords))\n",
        "print(keywords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "['AAAA', 'AAAC', 'AAAG', 'AAAT', 'AACA', 'AACC', 'AACG', 'AACT', 'AAGA', 'AAGC', 'AAGG', 'AAGT', 'AATA', 'AATC', 'AATG', 'AATT', 'ACAA', 'ACAC', 'ACAG', 'ACAT', 'ACCA', 'ACCC', 'ACCG', 'ACCT', 'ACGA', 'ACGC', 'ACGG', 'ACGT', 'ACTA', 'ACTC', 'ACTG', 'ACTT', 'AGAA', 'AGAC', 'AGAG', 'AGAT', 'AGCA', 'AGCC', 'AGCG', 'AGCT', 'AGGA', 'AGGC', 'AGGG', 'AGGT', 'AGTA', 'AGTC', 'AGTG', 'AGTT', 'ATAA', 'ATAC', 'ATAG', 'ATAT', 'ATCA', 'ATCC', 'ATCG', 'ATCT', 'ATGA', 'ATGC', 'ATGG', 'ATGT', 'ATTA', 'ATTC', 'ATTG', 'ATTT', 'CAAA', 'CAAC', 'CAAG', 'CAAT', 'CACA', 'CACC', 'CACG', 'CACT', 'CAGA', 'CAGC', 'CAGG', 'CAGT', 'CATA', 'CATC', 'CATG', 'CATT', 'CCAA', 'CCAC', 'CCAG', 'CCAT', 'CCCA', 'CCCC', 'CCCG', 'CCCT', 'CCGA', 'CCGC', 'CCGG', 'CCGT', 'CCTA', 'CCTC', 'CCTG', 'CCTT', 'CGAA', 'CGAC', 'CGAG', 'CGAT', 'CGCA', 'CGCC', 'CGCG', 'CGCT', 'CGGA', 'CGGC', 'CGGG', 'CGGT', 'CGTA', 'CGTC', 'CGTG', 'CGTT', 'CTAA', 'CTAC', 'CTAG', 'CTAT', 'CTCA', 'CTCC', 'CTCG', 'CTCT', 'CTGA', 'CTGC', 'CTGG', 'CTGT', 'CTTA', 'CTTC', 'CTTG', 'CTTT', 'GAAA', 'GAAC', 'GAAG', 'GAAT', 'GACA', 'GACC', 'GACG', 'GACT', 'GAGA', 'GAGC', 'GAGG', 'GAGT', 'GATA', 'GATC', 'GATG', 'GATT', 'GCAA', 'GCAC', 'GCAG', 'GCAT', 'GCCA', 'GCCC', 'GCCG', 'GCCT', 'GCGA', 'GCGC', 'GCGG', 'GCGT', 'GCTA', 'GCTC', 'GCTG', 'GCTT', 'GGAA', 'GGAC', 'GGAG', 'GGAT', 'GGCA', 'GGCC', 'GGCG', 'GGCT', 'GGGA', 'GGGC', 'GGGG', 'GGGT', 'GGTA', 'GGTC', 'GGTG', 'GGTT', 'GTAA', 'GTAC', 'GTAG', 'GTAT', 'GTCA', 'GTCC', 'GTCG', 'GTCT', 'GTGA', 'GTGC', 'GTGG', 'GTGT', 'GTTA', 'GTTC', 'GTTG', 'GTTT', 'TAAA', 'TAAC', 'TAAG', 'TAAT', 'TACA', 'TACC', 'TACG', 'TACT', 'TAGA', 'TAGC', 'TAGG', 'TAGT', 'TATA', 'TATC', 'TATG', 'TATT', 'TCAA', 'TCAC', 'TCAG', 'TCAT', 'TCCA', 'TCCC', 'TCCG', 'TCCT', 'TCGA', 'TCGC', 'TCGG', 'TCGT', 'TCTA', 'TCTC', 'TCTG', 'TCTT', 'TGAA', 'TGAC', 'TGAG', 'TGAT', 'TGCA', 'TGCC', 'TGCG', 'TGCT', 'TGGA', 'TGGC', 'TGGG', 'TGGT', 'TGTA', 'TGTC', 'TGTG', 'TGTT', 'TTAA', 'TTAC', 'TTAG', 'TTAT', 'TTCA', 'TTCC', 'TTCG', 'TTCT', 'TTGA', 'TTGC', 'TTGG', 'TTGT', 'TTTA', 'TTTC', 'TTTG', 'TTTT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zyvQXWoPtETD",
        "colab_type": "code",
        "outputId": "8e8495c3-a64f-4949-e952-c62b0210ed8b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  initialise the one-hot-vector!\n",
        "one_hot_vector = np.array([])\n",
        "\n",
        "#  initialise the one-hot-vector representations for reach class.\n",
        "class_1 = np.array([1,0,0,0])\n",
        "class_2 = np.array([0,1,0,0])\n",
        "class_3 = np.array([0,0,1,0])\n",
        "class_4 = np.array([0,0,0,1])\n",
        "for i in keywords:\n",
        "    for j in i:\n",
        "        if j=='A':\n",
        "            one_hot_vector = np.append(one_hot_vector, class_1)\n",
        "        elif j=='C':\n",
        "            one_hot_vector = np.append(one_hot_vector, class_2)\n",
        "        elif j=='G':\n",
        "            one_hot_vector = np.append(one_hot_vector, class_3)\n",
        "        elif j=='T':\n",
        "            one_hot_vector = np.append(one_hot_vector, class_4)\n",
        "#print(one_hot_vector)\n",
        "print(\"len(one_hot_vector)\", len(one_hot_vector))\n",
        "\n",
        "\n",
        "one_hot_vector_rep = np.split(one_hot_vector, len(one_hot_vector)/4)\n",
        "print(\"len(one_hot_vector_rep):\",len(one_hot_vector_rep))\n",
        "print(\"\\n one_hot_vector_rep: \\n\", one_hot_vector_rep)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(one_hot_vector) 4096\n",
            "len(one_hot_vector_rep): 1024\n",
            "\n",
            " one_hot_vector_rep: \n",
            " [array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.]), array([0., 0., 0., 1.])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RKyiogdAtETH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Our very own one-hot vector representation\n",
        "    Of the first_genome where k=1, in k-mers."
      ]
    },
    {
      "metadata": {
        "id": "xHZYCHhmtETI",
        "colab_type": "code",
        "outputId": "cfab24a2-985c-4dcd-9fbf-7d860158f956",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  initialise the one-hot-vector!\n",
        "one_hot_vector = np.array([])\n",
        "\n",
        "#  initialise the one-hot-vector representations for reach class.\n",
        "class_1 = np.array([1,0,0,0])\n",
        "class_2 = np.array([0,1,0,0])\n",
        "class_3 = np.array([0,0,1,0])\n",
        "class_4 = np.array([0,0,0,1])\n",
        "for i in first_genome:\n",
        "    if i=='A':\n",
        "        one_hot_vector = np.append(one_hot_vector, class_1)\n",
        "    elif i=='C':\n",
        "        one_hot_vector = np.append(one_hot_vector, class_2)\n",
        "    elif i=='G':\n",
        "        one_hot_vector = np.append(one_hot_vector, class_3)\n",
        "    elif i=='T':\n",
        "        one_hot_vector = np.append(one_hot_vector, class_4)\n",
        "print(one_hot_vector)\n",
        "print(\"len(one_hot_vector)\", len(one_hot_vector))\n",
        "print(\"len(first_genome)\",len(first_genome))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
            "len(one_hot_vector) 400\n",
            "len(first_genome) 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y-1k_nv7tETM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How they made theirs"
      ]
    },
    {
      "metadata": {
        "id": "1K1_lqRqtETQ",
        "colab_type": "code",
        "outputId": "0ef446b3-81c1-488f-ed34-62aeb6699279",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# initialise list\n",
        "human_genome = []\n",
        "\n",
        "def making_genome():\n",
        "    # make it add randomly to the list\n",
        "    for i in range(4):\n",
        "        a = random.randint(0,3)\n",
        "        if a==0:\n",
        "            human_genome.append('A')\n",
        "        elif a==1:\n",
        "            human_genome.append('C')\n",
        "        elif a==2:\n",
        "            human_genome.append('G')\n",
        "        elif a==3:\n",
        "            human_genome.append('T')\n",
        "    # return the list\n",
        "    return (human_genome)\n",
        "\n",
        "    \n",
        "#genome sequence with 100 such sequences.\n",
        "authors_genome = np.array([])\n",
        "for i in range(10):\n",
        "    authors_genome = np.append(authors_genome, np.asarray(making_genome()))\n",
        "print(\"authors_genome:\", authors_genome)\n",
        "print(\"len(authors_genome):\", len(authors_genome))\n",
        "\n",
        "\n",
        "#  initialise the one-hot-vector!\n",
        "one_hot_vector = np.array([])\n",
        "\n",
        "#  initialise the one-hot-vector representations for reach class.\n",
        "class_1 = np.array([1,0,0,0])\n",
        "class_2 = np.array([0,1,0,0])\n",
        "class_3 = np.array([0,0,1,0])\n",
        "class_4 = np.array([0,0,0,1])\n",
        "for i in authors_genome:\n",
        "    if i=='A':\n",
        "        one_hot_vector = np.append(one_hot_vector, class_1)\n",
        "    elif i=='C':\n",
        "        one_hot_vector = np.append(one_hot_vector, class_2)\n",
        "    elif i=='G':\n",
        "        one_hot_vector = np.append(one_hot_vector, class_3)\n",
        "    elif i=='T':\n",
        "        one_hot_vector = np.append(one_hot_vector, class_4)\n",
        "print(one_hot_vector)\n",
        "print(\"len(one_hot_vector)\", len(one_hot_vector))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "authors_genome: ['A' 'A' 'T' 'A' 'A' 'A' 'T' 'A' 'A' 'G' 'C' 'G' 'A' 'A' 'T' 'A' 'A' 'G'\n",
            " 'C' 'G' 'G' 'G' 'C' 'G' 'A' 'A' 'T' 'A' 'A' 'G' 'C' 'G' 'G' 'G' 'C' 'G'\n",
            " 'C' 'A' 'G' 'C' 'A' 'A' 'T' 'A' 'A' 'G' 'C' 'G' 'G' 'G' 'C' 'G' 'C' 'A'\n",
            " 'G' 'C' 'G' 'T' 'G' 'C' 'A' 'A' 'T' 'A' 'A' 'G' 'C' 'G' 'G' 'G' 'C' 'G'\n",
            " 'C' 'A' 'G' 'C' 'G' 'T' 'G' 'C' 'G' 'A' 'A' 'A' 'A' 'A' 'T' 'A' 'A' 'G'\n",
            " 'C' 'G' 'G' 'G' 'C' 'G' 'C' 'A' 'G' 'C' 'G' 'T' 'G' 'C' 'G' 'A' 'A' 'A'\n",
            " 'G' 'T' 'G' 'A' 'A' 'A' 'T' 'A' 'A' 'G' 'C' 'G' 'G' 'G' 'C' 'G' 'C' 'A'\n",
            " 'G' 'C' 'G' 'T' 'G' 'C' 'G' 'A' 'A' 'A' 'G' 'T' 'G' 'A' 'G' 'G' 'G' 'C'\n",
            " 'A' 'A' 'T' 'A' 'A' 'G' 'C' 'G' 'G' 'G' 'C' 'G' 'C' 'A' 'G' 'C' 'G' 'T'\n",
            " 'G' 'C' 'G' 'A' 'A' 'A' 'G' 'T' 'G' 'A' 'G' 'G' 'G' 'C' 'C' 'T' 'G' 'T'\n",
            " 'A' 'A' 'T' 'A' 'A' 'G' 'C' 'G' 'G' 'G' 'C' 'G' 'C' 'A' 'G' 'C' 'G' 'T'\n",
            " 'G' 'C' 'G' 'A' 'A' 'A' 'G' 'T' 'G' 'A' 'G' 'G' 'G' 'C' 'C' 'T' 'G' 'T'\n",
            " 'A' 'T' 'C' 'C']\n",
            "len(authors_genome): 220\n",
            "[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
            "len(one_hot_vector) 880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TmVVmkv9tETW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<b>We can also represent this as follows:</b> "
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "sU-wJZCLtETX",
        "colab_type": "code",
        "outputId": "2c3bf867-c0a7-41c3-fb3d-c43c21cf6655",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "one_hot_vector_rep = np.split(one_hot_vector, len(one_hot_vector)/4)\n",
        "print(\"len(one_hot_vector_rep):\",len(one_hot_vector_rep))\n",
        "print(\"\\n one_hot_vector_rep: \\n\", one_hot_vector_rep)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(one_hot_vector_rep): 220\n",
            "\n",
            " one_hot_vector_rep: \n",
            " [array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([1., 0., 0., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 0., 1., 0.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.]), array([0., 0., 0., 1.]), array([0., 0., 1., 0.]), array([0., 0., 0., 1.]), array([1., 0., 0., 0.]), array([0., 0., 0., 1.]), array([0., 1., 0., 0.]), array([0., 1., 0., 0.])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "inG6Ov7XtETZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Our next step is to transform the list of one-hot vectors into an image. \n",
        "For this purpose, we aim to assign each one-hot vector to a pixel. \n",
        "This gives us a 3-dimensional tensor, which is similar in shape to the tensor that serves as an input to image classification networks: the color of a pixel in an RGB-colored image is represented by a vector of length 3, while in our approach each pixel is represented by a one-hot vector of length 256."
      ]
    },
    {
      "metadata": {
        "id": "oXN75p9ltETa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## So, basically each pixel is now a one-hot vector of length 256"
      ]
    },
    {
      "metadata": {
        "id": "nxQz9PbctETb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For\n",
        "this purpose, we can make use of space-filling curves, as they can map 1-dimensional sequences to a 2-dimensional surface preserving continuity of the sequence (Bader, 2016; Aftosmis et al.,\n",
        "2004). Various types of space-filling curves are available."
      ]
    },
    {
      "metadata": {
        "id": "F9KNMhI9tETc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have compared the performance of\n",
        "several such curves, and concluded that Hilbert curves yield the best performance (Appendix A)."
      ]
    },
    {
      "metadata": {
        "id": "qZ9Ha6rKtETd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### By construction, the Hilbert curve yields a square image of size 2n x 2n, where n is the order of the curve (see Fig. 1).\n",
        "![Hilbert%20curve%20orders.png](attachment:Hilbert%20curve%20orders.png)\n",
        "\n",
        "\n",
        "However, a DNA sequence does not necessarily have 2n x 2n k-mers.\n",
        "\n",
        "\n",
        "\n",
        "In order to\n",
        "fit all k-mers into the image, we need to choose n such that 2n x 2n is at least the number of k-mers in\n",
        "the sequence, and since we do not wish to make the image too large, we pick the smallest such n.\n",
        "\n",
        "\n",
        "#### In many cases, a large fraction of the pixels then remains unused, as there are fewer k-mers than pixels in the image.\n",
        "![hilbert_cuurve_empty_space.png](attachment:hilbert_cuurve_empty_space.png)\n",
        "\n",
        "\n",
        "By construction, the used pixels are located in upper half of the image. Cropping\n",
        "the picture by removing the unused part of the image yields rectangular images, and increases the\n",
        "fraction of the image that is used (Figure 1e).\n",
        "![cropping_image_hilbert_curve.png](attachment:cropping_image_hilbert_curve.png)"
      ]
    },
    {
      "metadata": {
        "id": "L3qZ1AnptETd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "metadata": {
        "id": "cWwwxMs4tETe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Each pixel in the generated image is assigned a one-hot vector representing a k-mer. \n",
        "For increasing k, the length of the vector and thus the image dimension increases. Here, we use k = 4 resulting in 256 channels, which implies that each channel contains very sparse information. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Due to the curse of dimensionality standard network architectures applied to such images are prone to severe overfitting."
      ]
    },
    {
      "metadata": {
        "id": "DBgvfQfWtETf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Here, we design a specific CNN for the kind of high dimensional image that is generated from a DNA sequence. \n",
        "The architecture is inspired by ResNet (He et al., 2015) and Inception (Szegedy et al.,\n",
        "2015). \n",
        "\n",
        "- The network has L layers and,\n",
        "- each layer implements a non-linear function F <sub>l</sub> (x <sub>l</sub>) where,\n",
        "- l is the index of the hidden layer with output x <sub>l+1</sub>.\n",
        "- The function F <sub>l</sub> (x <sub>l</sub>) consists of various layers such as convolution (denoted by c), batch normalization (bn), pooling (p) and non-linear activation function (af)."
      ]
    },
    {
      "metadata": {
        "id": "D6p_x8amtETf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![network_architecture.png](attachment:network_architecture.png)"
      ]
    },
    {
      "metadata": {
        "id": "61eJIsMPtETg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first part of the network has the objective:\n",
        "- To reduce the sparseness of the input image (Figure 2), and consists of the consecutive layers [c; bn; c; bn; af; p]. \n",
        "- The main body of the network enhances the ability of the CNN to extract the relevant features from DNA space-filling curves. \n",
        "For this purpose, we designed a specific Computational Block inspired by the ResNet residual blocks (He et al., 2015). \n",
        "- The last part of the network consists of 3 fully-connected layers, \n",
        "- And softmax is used to obtain the output classification label. \n",
        "- The complete model is presented in Table 1, and code is available on Github (https://github.com/Bojian/Hilbert-CNN/tree/master). A simplified version of our network with two Computational Blocks is illustrated in Figure 2."
      ]
    },
    {
      "metadata": {
        "id": "OnLLYrROtETg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Computation Block. \n",
        "In the Computation Block,\n",
        "- first the outputs of two Residual Blocks and one identity mapping are summed, followed by a bn and an af layer (Figure 2).\n",
        "- In total, the computational block has 4 convolutional layers, two in each Residual Block (see Figure 3).\n",
        "- The Residual Block first computes the composite function of five consecutive layers, namely [c; bn; af; c; bn], followed by the concatenation of the output with the input tensor. The residual block concludes with an af.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- The Residual Block can be viewed as a new kind of non-linear layer denoted by Residuall[kj;kj+1;dlink;dout], where kj and kj+1 are the respective filter sizes of the two convolutional layers.\n",
        "- dlink and dout are the dimensions of the outputs of the first convolutional layer and the Residual Block, respectively, where dlink < dout; this condition simplifies the network architecture and reduces the computational cost. "
      ]
    },
    {
      "metadata": {
        "id": "zO4AYmTOtETh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Residual%20block%20detailed.png](attachment:Residual%20block%20detailed.png)"
      ]
    },
    {
      "metadata": {
        "id": "ZlJJTK6otETi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- The Computational Block can be denoted as  *C[k1;k2;k3;k4]*,\n",
        "with the two residual blocks defined as Residual1 *[k1;k2;dlink;dout]* and Residual2 *[k3;k4;dlink;dout]*. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Note that here we chose the same dlink and dout for both Residual\n",
        "Blocks in a Computational Block."
      ]
    },
    {
      "metadata": {
        "id": "0etJDmgutETj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![computation_block_detailed.png](attachment:computation_block_detailed.png)"
      ]
    },
    {
      "metadata": {
        "id": "_YdBtRTmtETj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementation details:\n",
        "- Most convolutional layers use small squared filters of size 2, 3 and 4, <u>*except for the layers in the first part of the network, where large filters are applied to capture long range features.*</u>\n",
        "\n",
        "#### Let us talk about Vanishing Gradient at this point.\n",
        "![gradient%20descent.gif](attachment:gradient%20descent.gif)\n",
        "<i>https://independentseminarblog.com/2018/01/12/moving-below-the-surface-3-gradient-descent-william/</i>\n",
        "\n",
        "- As we can recall, that the gradient at any point is the product of previous gradients upto that point.\n",
        "- And as the gradient back-propogates, the slope of the curve becomes less steeper. \n",
        "- This causes the gradients at the later stages of NN to be of very small values, \n",
        "- And as we know that the product of value between 0 and 1 is always smaller than both the original values, \n",
        "- So the gradient value decreases as the network learns, causing the gradients at the early layers to \"vanish\".\n",
        "- This is an Issue because the early layers are responsible for extracting the base features and are the building blocks of our network.\n",
        "<br><br>\n",
        "#### And that is why,\n",
        "<br>\n",
        "- We use <b>Exponential Linear Units (ELU, Clevert et al. (2015))</b> as <u>our activation function af</u> to reduce the effect of gradient vanishing: preliminary experiments showed that ELU preformed significantly better than other activation functions (data not shown).\n",
        "![ELU.png](attachment:ELU.png)\n",
        "\n",
        "Title:Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)<br>\n",
        "Authors:\tClevert, Djork-ArnÃ©; Unterthiner, Thomas; Hochreiter, Sepp<br>\n",
        "Publication:\teprint arXiv:1511.07289<br>\n",
        "Publication Date:\t11/2015<br>\n",
        "Origin:\tARXIV<br>\n",
        "Keywords:Computer Science - Learning<br>\n",
        "Comment:Published as a conference paper at ICLR 2016<br>\n",
        "Bibliographic Code:2015arXiv151107289C<br>\n",
        "link: https://arxiv.org/abs/1511.07289<br>\n",
        "\n",
        "- For the <u>pooling layers p</u> we used <b>Average pooling</b>. Average pooling outperformed Max pooling in terms of prediction accuracy by more than 2% in general, as it reduces the high variance of the sparse generated images. \n",
        "- <b>Cross entropy</b> was used as the <u>loss function</u>."
      ]
    },
    {
      "metadata": {
        "id": "qgkgJadstETl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Architecture_table.png](attachment:Architecture_table.png)"
      ]
    },
    {
      "metadata": {
        "id": "SqNg4OCptETm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Datasets used:\n",
        "![Dataset_table.png](attachment:Dataset_table.png)"
      ]
    },
    {
      "metadata": {
        "id": "HrgJ8ZV1tETn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<b>A randomly chosen 90% of the dataset is used for training the network, 5% is used for validation\n",
        "and early stopping, and the remaining (5%) is used for evaluation.</b>"
      ]
    },
    {
      "metadata": {
        "id": "eFEXTNSmtETn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<b>We train the network using the\n",
        "AdamOptimizer(Adaptive Moment Optimisation) </b>\n",
        "- We find the first moment(the mean) and the second moment(un-centered variance) with respect to gradient and use them to update the parameters.\n",
        "![Long%20Valley%20-%20Imgur.gif](attachment:Long%20Valley%20-%20Imgur.gif)\n",
        "<i>http://3.bp.blogspot.com/-nrtJPrdBWuE/VPmIB46F2aI/AAAAAAAACCw/vaE_B0SVy5k/s1600/Long%2BValley%2B-%2BImgur.gif</i>\n",
        "\n",
        "<br>\n",
        "As we can see from the above visualisation of the learning process, the adaptive algorithms(the last three) tend to converge faster than the rest."
      ]
    },
    {
      "metadata": {
        "id": "Nhx2-GRytETo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- The learning rate is set to 0.003\n",
        "- the batch-size was set to 300 samples\n",
        "- the maximum number of epochs is 10."
      ]
    },
    {
      "metadata": {
        "id": "tF6hCtahtETp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- After each epoch the level of generalization is measured as the accuracy obtained on the validation set. \n",
        "- We use early stopping to prevent overfitting.\n",
        "- To ensure the model stops at the correct time, we combine the GL<sub>alpha</sub> measurement (Prechelt,\n",
        "1998) of generalization capability and the No-Improvement-In-N-Steps(Nii-N) method (Prechelt,1998).\n",
        "- For instance, Nii-2 means that the training process is terminated when generalization capability is not improved in two consecutive epochs.\n",
        "\n",
        "###### which basically means: \n",
        "They stop training the network as soon as the results are stagnant over the defined number of < *<u>Nii</u>* > epochs. Where Nii is just a number."
      ]
    },
    {
      "metadata": {
        "id": "BoUcZCVrtETq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Types of Testing done by authors:\n",
        "\n",
        "###  We compare the performance of our approach:\n",
        "- One of these is the support vector machine (SVM) model by Higashihara et al. (2008), for which results are available in their paper. \n",
        "- Second, in tight communication with the authors, we reconstructed the Seq-CNN model presented in Nguyen et al. (2016) (the original software was no longer available), see Appendix C for detailed settings.\n",
        "- Third, we constructed the commonly used LSTM, where the so-called 4-mer profile of the sequence is used as input. A 4-mer profile is a list containing the number of occurrences of all 256 4-mers of the alphabet {A,C,G,T} in a sequence. Preliminary tests showed that using all 256 4-mers resulted in overfitting, and including only the 100 most frequent 4-mers is sufficient. Details of the LSTM architecture can be found in Table 8 in Appendix C.\n",
        "\n",
        "### In order to assess the effect of using a 2D representation of the DNA sequence in isolation\n",
        "- We compare HCNN to a neural network using a sequential representation as input. We refer to this model as <b>seq-HCNN</b>. \n",
        "- As in HCNN, the DNA sequence is converted into a list of kmer representing one-hot vectors, though the mapping of the sequence into a 2D image is omitted. The network architecture is a â€œflattenedâ€ version of the one used in HCNN: \n",
        "- for example, a 7x7 convolution filter in HCNN is transformed to a 49x1 convolution filter in the 1D-sequence model.\n",
        "- As a summary of model size, the Seq-CNN model contains 1.1M parameters, while both HCNN and seq-HCNN have 961K parameters, and the LSTM has 455K parameters.\n",
        "### In order to test whether our method is also applicable to DNA sequence classification tasks other than chromatin state prediction only\n",
        "- We performed additional tests on the splice-junction gene sequences dataset from Lichman (2013). \n",
        "- Most of the DNA sequence is unused, and splice-junctions refer to positions in the genetic sequence where the transition from an unused subsequence (intron) to a used subsequence (exon) or vice versa takes place.\n",
        "- The dataset consists of DNA subsequences of length 61, and each of the sequences is known to be an intron-to-exon splice-junction, an exon-to-intron splice junction or neither. As the dataset is relatively small, we used 1-mers instead of 4-mers.\n",
        "- Note that the sequences are much shorter than for the other datasets, resulting in smaller images (dimensions 8 x 8 x 4)."
      ]
    },
    {
      "metadata": {
        "id": "Wy6WOY-WtETq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Results:\n",
        "\n",
        "- The results show that SVM and Seq-CNN were both outperformed by HCNN and seq-HCNN;\n",
        "- LSTM shows poor performance.\n",
        "- HCNN and seq-HCNN show similar performance in terms of prediction accuracy, though HCNN shows more consistent results over the ten folds indicating that using a 2D representation of the sequence improves robustness.\n",
        "<br>\n",
        "![accuracies_comparisons.png](attachment:accuracies_comparisons.png)\n",
        "<br><br><br><br><br><br>\n",
        "- Furthermore, HCNN yields better performance than seq-HCNN in terms of precision, recall, AP and AUC (Table 5). It thus enables to reliably vary the tradeoff between recall and false discoveries. HCNN outperforms all methods in terms of training time (Table 4).\n",
        "<br>\n",
        "![training_times_comparison.png](attachment:training_times_comparison.png)"
      ]
    },
    {
      "metadata": {
        "id": "mWJMVe_dtETr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Discussion\n",
        "We believe that the improved performance over the CNN developed by Nguyen et al. (2016) (Seq-\n",
        "CNN) is a result of three factors. \n",
        "- First, our network uses larger convolutional filters, allowing the model to detect long-distance interactions. \n",
        "- Second, despite HCNN being deeper, both HCNN and seq-HCNN have a smaller number of parameters, allowing for faster optimization. This is due to the size of the layer preceding the fully connected layer, which is large in the method proposed by Nguyen et al. (2016) and thus yields a huge number of parameters in the fully connected layer. In HCNN on the other hand the number of nodes is strongly reduced before introducing a fully connected layer. \n",
        "- Third, the use of a two-dimensional input further enhances the modelâ€™s capabilities of incorporating long-term interactions."
      ]
    },
    {
      "metadata": {
        "id": "D78bnsbStETr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We showed that seq-HCNN and HCNN are not only capable of predicting chromatin state, but can\n",
        "also predict the presence or absence of splice-junctions in DNA subsequences. \n",
        "<br><br>\n",
        "This suggests that our approach could be useful for DNA sequence classification problems in general.\n",
        "<br><br>\n",
        "Hilbert curves have several properties that are desirable for DNA sequence classification. The intuitive\n",
        "motivation for the use of Hilbert curves is supported by good results when comparing Hilbert\n",
        "curves to other space-filling curves. Additionally, Hilbert curves have previously been shown to be\n",
        "useful for visualization of DNA sequences (Anders, 2009).<br><br>\n",
        "The main limitation of Hilbert curves is their fixed length, which implies that the generated image\n",
        "contains some empty spaces. These spaces consume computation resources; nevertheless, the 2D\n",
        "representation still yields reduced training times compared to the 1D-sequence representation, presumably\n",
        "due to the high degree of optimization for 2D inputs present in standard CNN frameworks.<br><br>\n",
        "Given that a substantial part of the improvements in performance rates are due to our novel architecture,\n",
        "we plan on investigating the details of how components of the architecture are intertwined with\n",
        "improvements in prediction performance in more detail. We also plan to further investigate why\n",
        "Hilbert curves yield the"
      ]
    }
  ]
}